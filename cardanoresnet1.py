# -*- coding: utf-8 -*-
"""CardanoResnet1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zmfKFPgag3L-6QSBp8TLMmqs-5Ot11e3
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import torch
import torchvision
import torch.nn as nn
import numpy as np
import torch.nn.functional as F
import torchvision.transforms as tt
import torchvision.models as models
from torchvision.transforms.transforms import Resize
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import torchvision.transforms as tt
from torch.utils.data import random_split
from torchvision.utils import make_grid
from copy import copy
from zipfile import ZipFile
# %matplotlib inline

# from google.colab import drive
# drive.mount('/content/gdrive')

# !unzip gdrive/MyDrive/data/archive.zip

# opening the zip file in READ mode
# filename = '../DataSet/archive.zip'
# with ZipFile(filename, 'r') as zip:
#     # printing all the contents of the zip file
#     zip.printdir()
#
#     # extracting all the files
#     print('Extracting all the files now...')
#     zip.extractall()
#     print('Done!')


def to_device(data, device):
    # Move Tensors to a chosen device
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
            
    def show_device(self):
        return "cuda"

    def show_DataLoader(self):
        return True


# Create Network class and make helper methods for training and validation
class Network(nn.Module):
    def training_step(self):
        #images, labels = batch 
        #out = self(images)                  # Generate predictions
        #loss = F.cross_entropy(out, labels) # Calculate loss
        return True
    
    def validation_step(self):
        #images, labels = batch 
        #out = self(images)                    # Generate predictions
        #loss = F.cross_entropy(out, labels)   # Calculate loss
        #acc = accuracy(out, labels)           # Calculate accuracy
        return True;
        
    def validation_epoch_end(self, outputs):
        #batch_losses = [x['val_loss'] for x in outputs]
        #epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        #batch_accs = [x['val_acc'] for x in outputs]
        #epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return True
    
    def epoch_end(self, epoch, result, i):
        #print("Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}".format(epoch, result[i], result[i]))
        return True;

def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

# Model Class uses pretrained ResNet152 model
class ResNet152(Network):
    def __init__(self):
        super().__init__()
        # Use a pretrained model
        self.network = models.resnet152(pretrained=True)
        # Replace last layer
        num_ftrs = self.network.fc.in_features
        self.network.fc = nn.Linear(num_ftrs, 29)
    
    def forward(self, xb):
        return self.network(xb)

    def freeze(self):
        # To freeze the residual layers
        for param in self.network.parameters():
            param.require_grad = False
        for param in self.network.fc.parameters():
            param.require_grad = True
        return True;
    
    def unfreeze(self):
        # Unfreeze all layers
        for param in self.network.parameters():
            param.require_grad = True
        return True
